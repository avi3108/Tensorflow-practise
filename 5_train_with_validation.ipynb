{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 00:47:28.423850: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-17 00:47:34.033722: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/avi/Downloads/aws_kinesis/amazon-kinesis-video-streams-producer-sdk-cpp/open-source/local/lib\n",
      "2023-02-17 00:47:34.033836: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-17 00:48:07.823452: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/avi/Downloads/aws_kinesis/amazon-kinesis-video-streams-producer-sdk-cpp/open-source/local/lib\n",
      "2023-02-17 00:48:07.823714: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/avi/Downloads/aws_kinesis/amazon-kinesis-video-streams-producer-sdk-cpp/open-source/local/lib\n",
      "2023-02-17 00:48:07.823732: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_horse = os.path.join(\"images/train/horses\")\n",
    "train_human = os.path.join(\"images/train/humans\")\n",
    "\n",
    "valid_horse = os.path.join(\"validation/horses\")\n",
    "valid_human = os.path.join(\"validation/humans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "train_horse_dir = os.listdir(train_horse)\n",
    "train_human_dir = os.listdir(train_human)\n",
    "\n",
    "valid_horse_dir = os.listdir(valid_horse)\n",
    "valid_human_dir = os.listdir(valid_human)\n",
    "\n",
    "print(len(valid_human_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_img = ImageDataGenerator(rescale=1/255)\n",
    "valid_img = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_generator = train_img.flow_from_directory(\n",
    "    \"./images/train/\",\n",
    "    target_size = (300,300),\n",
    "    batch_size =128,\n",
    "    class_mode = 'binary'\n",
    ")\n",
    "  \n",
    "validation_generator = valid_img.flow_from_directory(\n",
    "    \"./validation/\",\n",
    "    target_size = (300,300),\n",
    "    batch_size =32,\n",
    "    class_mode = 'binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 00:48:33.379428: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/avi/Downloads/aws_kinesis/amazon-kinesis-video-streams-producer-sdk-cpp/open-source/local/lib\n",
      "2023-02-17 00:48:33.379457: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-17 00:48:33.379473: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (avi): /proc/driver/nvidia/version does not exist\n",
      "2023-02-17 00:48:33.379690: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation = \"relu\",input_shape=(300,300,3)),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation = \"relu\" ),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation = \"relu\" ),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation = \"relu\" ),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation = \"relu\" ),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512,activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1,activation = \"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 298, 298, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 149, 149, 16)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 147, 147, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 73, 73, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 71, 71, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 35, 35, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 33, 33, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 16, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1606144   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,704,097\n",
      "Trainable params: 1,704,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import  RMSprop\n",
    "model.compile(loss= \"binary_crossentropy\", optimizer=RMSprop(learning_rate =0.001),metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 00:48:45.966802: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 727482368 exceeds 10% of free system memory.\n",
      "2023-02-17 00:48:48.890998: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 727482368 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8 [==>...........................] - ETA: 1:01 - loss: 0.6930 - accuracy: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 00:48:49.992762: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 727482368 exceeds 10% of free system memory.\n",
      "2023-02-17 00:48:52.908110: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 727482368 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/8 [======>.......................] - ETA: 24s - loss: 0.6909 - accuracy: 0.5039 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 00:48:54.039941: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 727482368 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 50s 6s/step - loss: 0.7039 - accuracy: 0.5228 - val_loss: 0.9633 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 44s 5s/step - loss: 0.6718 - accuracy: 0.6062 - val_loss: 0.9270 - val_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 50s 6s/step - loss: 0.6758 - accuracy: 0.5469 - val_loss: 0.5869 - val_accuracy: 0.8164\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 45s 6s/step - loss: 0.5121 - accuracy: 0.7764 - val_loss: 7.7884 - val_accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 45s 6s/step - loss: 0.5628 - accuracy: 0.8420 - val_loss: 0.7419 - val_accuracy: 0.6875\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 45s 5s/step - loss: 0.3567 - accuracy: 0.8487 - val_loss: 0.5326 - val_accuracy: 0.7930\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 44s 5s/step - loss: 0.2202 - accuracy: 0.9255 - val_loss: 0.4886 - val_accuracy: 0.7734\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 44s 5s/step - loss: 0.3620 - accuracy: 0.9344 - val_loss: 0.5806 - val_accuracy: 0.8555\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 44s 6s/step - loss: 0.1652 - accuracy: 0.9466 - val_loss: 1.5377 - val_accuracy: 0.7930\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 44s 5s/step - loss: 0.3092 - accuracy: 0.8977 - val_loss: 0.5073 - val_accuracy: 0.7578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc238b8bed0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=8,\n",
    "    epochs = 10,\n",
    "    verbose =1 ,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = 8\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.78031206]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "load_img = image.load_img(\"test_images/human1.jpg\",target_size=(300,300))\n",
    "img_array = image.img_to_array(load_img)\n",
    "x = np.expand_dims(img_array,axis=0)\n",
    "x/=255\n",
    "score = model.predict(x)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "146d8846a7a671f14a52572341ae3d686be6aad2eb4af8271194ae862a45bab5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
